---
title: "Flexible Models, Within-Country Heterogeneity, and Out-of-Sample Prediction"
author: "Carlisle Rainey & Florian M. Hollenbach"
date: "September 9, 2015"
output: pdf_document
---

Out-of-Sample prediction ought to be the gold standard of theory evaluation. In fact, out-of-sample prediction is a necessary condition of a causal argument. On the other hand, prediction is not a sufficient condition for the discovery of a causal effect. This is especially true for unstructured, non-parametric models that become more and more common in political science. While we advocate for theory building and testing using out-of-sample prediction, we show that scholars have to be extremely careful in designing the cross-validation procedures and modeling choices. Moreover, depending on the structure of the data, constraining models (i.e. parameterization) based on careful evaluation can be important. Non-parametric models are no panecae to prediction and theory testing in an interdependent world. 

1. We posit that for a general theory to make arguments about a causal effect, it ought to have true out-of-sample predictive power. In particular, the theory should allow for the prediction of truly new cases (e.g. countries, states, cities, individuals) and must have some predictive power on these cases. (I wonder if it is possible to derive something like this from Rubin)

2. ML algorithms very strongly assume independence, more so than OLS, etc.

3. if ML is used for theory evaluation or EDA, the structure of the data becomes very important. Clustering on X & Y (fixed effects) can lead to the overvalueing of variables with high between country variance (or high btw/within variance ratio) and that are correlated with y. 

4. even if clustering in x is unrelated to y, the structure in linear models may actually aid out-of-sample prediction (with new cases).











This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
summary(cars)
```

You can also embed plots, for example:

```{r, echo=FALSE}
plot(cars)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

## Simple Example with GAMs

Claim: Suppose you are interested in predicting a new observation $y_{new}$ from $x_{new}$ for an unobserved group. This group might simply fall outside the training set. Now suppose a true model $y_{ij} = x_{ij} + \gamma_j + \epsilon_{ij}$, where $x_{ij}$ is fixed, $\gamma_j \sim N(0, \sigma^2_{\gamma})$, and $\epsilon_{ij} \sim N(0, \sigma^2_{\epsilon})$. 

```{r, echo=FALSE}
# set seed
set.seed(8972354)

# parameters
n_groups <- 10
n_times <- 100
sd_alpha <- 20
sd_gamma <- 20
sd_epsilon <- 1

# create variables
groups <- 1:n_groups
years <- seq(2000 - n_times + 1, 2000)
df <- data.frame(expand.grid(group = groups, year = years, KEEP.OUT.ATTRS = FALSE))

# simulate data
group_alpha <- seq(-50, 50, length.out = n_groups) #runif(n_groups, -1*sd_alpha, sd_alpha)
group_gamma <- rnorm(n_groups, sd = sd_gamma)
df$x <- group_alpha[df$group] + rnorm(n_groups*n_times, sd = 1)
df$y <- df$x + group_gamma[df$group] + rnorm(n_groups*n_times, sd = sd_epsilon)

# plot data
library(ggplot2)
ggplot(df, aes(x, y)) + 
	geom_point(aes(color = factor(group)), alpha = 0.5) + 
	geom_smooth(se = FALSE) + 
	geom_smooth(method = "lm", se = FALSE) + 
	geom_abline(intercept = 0, slope = 1)
```
